# backend/main.py

from fastapi import FastAPI, UploadFile, File
from fastapi.responses import JSONResponse
import os, shutil, torch
from torchvision.models import efficientnet_b0
import torch.nn as nn
from PIL import Image
from torchvision import transforms
from utils.extract_frames import extract_frames
from utils.download import maybe_download_model  # âœ… ì¶”ê°€

from fastapi.middleware.cors import CORSMiddleware

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# âœ… ëª¨ë¸ ìžë™ ë‹¤ìš´ë¡œë“œ
maybe_download_model()

# ---------------------------
# ëª¨ë¸ ë¡œë”©
# ---------------------------
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = efficientnet_b0(weights=None)
model.classifier[1] = nn.Linear(model.classifier[1].in_features, 1)
model.load_state_dict(torch.load("checkpoints/deepfake_efficientnet.pth", map_location=DEVICE))
model.eval().to(DEVICE)

# ---------------------------
# ì „ì²˜ë¦¬ ì •ì˜
# ---------------------------
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
])

# ---------------------------
# API ì—”ë“œí¬ì¸íŠ¸
# ---------------------------
@app.post("/analyze")
async def analyze_video(file: UploadFile = File(...)):
    temp_video_path = "temp_video.mp4"
    temp_frame_dir = "temp_frames"

    with open(temp_video_path, "wb") as f:
        shutil.copyfileobj(file.file, f)

    print("âœ… ì—…ë¡œë“œ íŒŒì¼ ì €ìž¥ ì™„ë£Œ")

    os.makedirs(temp_frame_dir, exist_ok=True)
    num_frames = extract_frames(temp_video_path, temp_frame_dir, max_frames=32)
    print(f"ðŸ“¸ ì¶”ì¶œëœ í”„ë ˆìž„ ìˆ˜: {num_frames}")

    if num_frames == 0:
        return JSONResponse(status_code=400, content={"error": "í”„ë ˆìž„ ì¶”ì¶œ ì‹¤íŒ¨"})

    try:
        inputs = []
        for i in range(num_frames):
            frame_path = os.path.join(temp_frame_dir, f"frame_{i:03d}.jpg")
            img = Image.open(frame_path).convert("RGB")
            inputs.append(transform(img))
        input_tensor = sum(inputs) / len(inputs)
        input_tensor = input_tensor.unsqueeze(0).to(DEVICE)

        with torch.no_grad():
            output = model(input_tensor)
            prob = torch.sigmoid(output).item()

        print(f"ðŸ§  ì˜ˆì¸¡ ê²°ê³¼: {prob:.4f}")
    except Exception as e:
        print(f"âŒ ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return JSONResponse(status_code=500, content={"error": "ì¶”ë¡  ì‹¤íŒ¨"})

    os.remove(temp_video_path)
    shutil.rmtree(temp_frame_dir)

    return {
        "deepfake_probability": round(prob * 100, 2),
        "prediction": "FAKE" if prob > 0.5 else "REAL"
    }


@app.get("/")
def health_check():
    return {"status": "âœ… Deepfake API is running."}
